---
layout: post
title: RAG知识库在房产领域的落地实践：从多路召回、重排到精准问答
---

{{ page.title }}
================

<p class="meta">08 Otc 2025 - 北京</p>


### 1、背景：为什么需要构建交易领域的 RAG 系统？

在房产交易这一高度专业化、政策敏感且地域差异显著的领域，用户咨询问题往往具备以下特点：

- **强场景性**：如“客户已婚，男女方都不是北京人，北京五环内有一套住房，家里有未成年一儿一女……请问适用北京二孩政策吗？”
- **高准确性要求**：涉及贷款成数、利率、限购资格等，容错率极低。
- **知识更新频繁**：各地购房政策、贷款规则按月甚至按周调整。
- **地域差异大**：各城市的政策体系完全不同。

### 2、整体架构与流程

**“多路召回 + 智能融合 + 重排序 + 约束生成”** 的端到端 RAG 流程：

![](/pic/2025/10-08-1.jpg)

* **输入理解：** 通过规则和HTTP接口补充用户城市ucid等基本信息，然后通过LLM模型对核心问题提取。
* **多路召回：**
    * 结构化路径：graph_db_query —— 基于知识标题精确匹配。
    * 语义路径：graph_vector_query —— 分别召回 QA知识、知识点、专家生产 三类内容。
* **知识融合：** Python 节点对多源结果去重、过滤、排序。
* **重排序（Rerank）：** 使用 BGE-reranker 模型 对召回结果按 query 相关性重新打分。
* **约束生成：** LLM Prompt 强制要求“仅基于参考内容回答”，否则返回兜底话术。

### 3、问题与解决方案

* **I、多源知识重复与冲突：** 同一政策可能同时存在于“QA知识”和“知识点”中，内容略有差异，导致 LLM 混淆。

解决方案：基于 ID 的严格去重 + 内容频次加权
  在 Python 融合节点中，我们实现了一套去重逻辑：

```
python：
多源知识融合
for item in all_sources:
    vdb_id = item['id'] or item['vdbId']
    if vdb_id not in seen_ids:  # 【关键】按唯一ID去重
        seen_ids.add(vdb_id)
        content_counter[item['text']] += 1

# 按出现频次排序：高频内容优先
sorted_contents = sorted(contents, key=lambda x: -content_counter[x])
```
* **II、无效/脏数据干扰：** 知识库中存在占位符如 "？\n空"，若被召回将导致 LLM 输出无意义内容。

解决方案：硬过滤 + 动态清洗
在融合阶段显式过滤：

```
python:
if "？\\n空" not in content:
    result.append(content)
    
```

* **III 专家知识被淹没：** “专家生产”内容权威性高，但在向量检索中可能因表述专业而相似度偏低。
解决方案：独立通道 + 高优先级展示
  将 专家生产 类知识单独存入 expert_contents；
  在最终输出中，优先拼接专家内容，确保其不被普通知识点覆盖。

* **IV、LLM 自由发挥（幻觉）：** 即使提供了正确参考，LLM 仍可能添加“一般来说”、“建议咨询”等模糊表述。
Prompt 核心指令：


```
prompt:
你必须严格根据以下【参考内容】回答。
如果【参考内容】中没有相关信息，请回答：“根据现有资料无法回答。”
不得使用“可能”、“一般来说”、“我认为”等模糊或主观表述。

```
后处理规则：

```
python:
if any(phrase in answer for phrase in ["一般来说", "建议"]):
    return "根据现有资料无法回答。"
    
```

### 4、未来优化方向
* **引入混合检索：** 结合 BM25 关键词 + 向量检索，提升召回率。
* **动态知识更新：** 对接政策发布平台，实现分钟级热更新。
* **强化评估体系：** 构建自动化 Bad Case 回流机制，驱动迭代。

最后：RAG 不是简单的“检索+生成”，而是一套**系统工程**。在房产这种高 stakes 场景中，我们必须通过**严谨的召回策略、可靠的融合逻辑、强约束的生成机制，** 才能构建真正可信的 AI 助手。